{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining optimum vocabulary size\n",
    "\n",
    "Excluding `genres`, as vocabulary is used only for `overview`. We need to\n",
    "determine the value of `vocab_size` below which recommendation quality dips\n",
    "appreciably. If we don't exclude `genres`, we won't see a sharp dip in\n",
    "quality, because `genres` will come to the rescue of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.join('..'))\n",
    "from recommender.preprocessing import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modified version of `recommender.model.Recommender`, with `genres` not used to\n",
    "generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "from enum import Enum\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# from .preprocessing import *\n",
    "\n",
    "KEEP_COLUMNS = ['genres', 'overview', 'keywords']\n",
    "\n",
    "FILENAME_ENCODER_GENRES = 'encoder_genres.pkl'\n",
    "FILENAME_VECTORIZER_OVERVIEW = 'vectorizer_overview.pkl'\n",
    "FILENAME_SVD = 'svd.pkl'\n",
    "\n",
    "class EmbedderMode(Enum):\n",
    "    TRAIN = 'train'\n",
    "    INFER = 'infer'\n",
    "\n",
    "    @classmethod\n",
    "    def values(cls):\n",
    "        return [e.value for e in cls]\n",
    "\n",
    "class Embedder:\n",
    "    def __init__(self):\n",
    "        self.encoder_genres = None\n",
    "        self.vectorizer_overview = None\n",
    "        self.svd = None\n",
    "\n",
    "    def train(self, media, vocab_size=None, embedding_dim=None):\n",
    "        self.pipeline(media, EmbedderMode.TRAIN, vocab_size=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "    def embed(self, media, save_path=None):\n",
    "        embeddings, ids = self.pipeline(media, EmbedderMode.INFER)\n",
    "        if save_path:\n",
    "            logging.info(f'Saving embeddings to \"{save_path}\"')\n",
    "            np.savez(save_path, embeddings=embeddings, ids=ids)\n",
    "        return embeddings, ids\n",
    "\n",
    "    def pipeline(self, media, mode, vocab_size=None, embedding_dim=None):\n",
    "        assert mode.value in EmbedderMode.values()\n",
    "\n",
    "        logging.info(f'{self.__class__.__name__} in [{mode.value}] mode.')\n",
    "\n",
    "        media = media.loc[:, KEEP_COLUMNS]\n",
    "        ids = media.index.to_numpy()\n",
    "\n",
    "        # logging.info('Preprocessing \\'genres\\'')\n",
    "        # media['genres'] = media['genres'].apply(extract_genre_names)\n",
    "\n",
    "        # logging.info('Encoding \\'genres\\'')\n",
    "        # if mode == EmbedderMode.TRAIN:\n",
    "        #     self.encoder_genres = MultiLabelBinarizer()\n",
    "        #     encoded_genres = self.encoder_genres.fit_transform(media['genres'])\n",
    "        # else:\n",
    "        #     encoded_genres = self.encoder_genres.transform(media['genres'])\n",
    "\n",
    "        logging.info('Preprocessing \\'overview\\'')\n",
    "        media['overview'] = media['overview'].fillna('')\n",
    "\n",
    "        # logging.info('Injecting \\'keywords\\' into \\'overview\\'')\n",
    "        # media = inject_keywords(media)\n",
    "\n",
    "        logging.info(f'Vectorizing \\'overview\\'...')\n",
    "        time_start = timer()\n",
    "        if mode == EmbedderMode.TRAIN:\n",
    "            self.vectorizer_overview = TfidfVectorizer(\n",
    "                strip_accents=False,\n",
    "                lowercase=False,\n",
    "                preprocessor=None,\n",
    "                tokenizer=None,\n",
    "                analyzer=normalize,\n",
    "                norm='l2',\n",
    "                max_features=vocab_size\n",
    "            )\n",
    "            vectorized_overview = self.vectorizer_overview.fit_transform(media['overview'])\n",
    "        else:\n",
    "            vectorized_overview = self.vectorizer_overview.transform(media['overview'])\n",
    "        logging.info(f'Vectorizing \\'overview\\' took {round(timer() - time_start, 4)} s, for a vocabulary size of {len(self.get_vocab())}.')\n",
    "\n",
    "        # logging.info(f'Stacking vectorized overview onto encoded \\'genres\\'')\n",
    "        # embeddings = hstack([encoded_genres, vectorized_overview], format='csr')\n",
    "        embeddings = vectorized_overview\n",
    "\n",
    "        if mode == EmbedderMode.TRAIN:\n",
    "            if embedding_dim:\n",
    "                logging.info(f'Reducing dimension to {embedding_dim}...')\n",
    "                time_start = timer()\n",
    "                self.svd = TruncatedSVD(n_components=embedding_dim, algorithm='arpack')\n",
    "                self.svd.fit(embeddings)\n",
    "                logging.info(f'Dimensionality reduction took {round(timer() - time_start)} s.')\n",
    "        else:\n",
    "            if self.svd:\n",
    "                logging.info(f'Reducing dimension to {embedding_dim}...')\n",
    "                time_start = timer()\n",
    "                embeddings = self.svd.transform(embeddings)\n",
    "                logging.info(f'Dimensionality reduction took {round(timer() - time_start)} s.')\n",
    "\n",
    "                logging.info('Sparsifying embeddings...')\n",
    "                time_start = timer()\n",
    "                embeddings = csr_matrix(embeddings)\n",
    "                logging.info(f'Sparsifying embeddings took {round(timer() - time_start)} s.')\n",
    "\n",
    "        if mode == EmbedderMode.INFER:\n",
    "            return embeddings, ids\n",
    "\n",
    "    # def get_genres(self):\n",
    "    #     return self.encoder_genres.classes_\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return self.vectorizer_overview.get_feature_names_out()\n",
    "\n",
    "    def get_embedding_dim(self):\n",
    "        return self.svd.n_components_\n",
    "\n",
    "    def save(self, model_path):\n",
    "        # with open(os.path.join(model_path, FILENAME_ENCODER_GENRES), 'w') as f:\n",
    "        #     pickle.dump(self.encoder_genres, f)\n",
    "        with open(os.path.join(model_path, FILENAME_VECTORIZER_OVERVIEW), 'w') as f:\n",
    "            pickle.dump(self.vectorizer_overview, f)\n",
    "        if self.svd:\n",
    "            with open(os.path.join(model_path, FILENAME_SVD), 'w') as f:\n",
    "                pickle.dump(self.svd, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, model_path):\n",
    "        embedder = cls()\n",
    "        # with open(os.path.join(model_path, FILENAME_ENCODER_GENRES), 'r') as f:\n",
    "        #     embedder.encoder_genres = pickle.load(f)\n",
    "        with open(os.path.join(model_path, FILENAME_VECTORIZER_OVERVIEW), 'r') as f:\n",
    "            embedder.vectorizer_overview = pickle.dump(f)\n",
    "\n",
    "        svd_path = os.path.join(model_path, FILENAME_SVD)\n",
    "        if os.path.exists(svd_path):\n",
    "            with open(svd_path, 'r'):\n",
    "                embedder.svd = pickle.load(f)\n",
    "        else:\n",
    "            embedder.svd = None\n",
    "\n",
    "        return embedder\n",
    "\n",
    "    @staticmethod\n",
    "    def load_embeddings(embeddings_dir):\n",
    "        embeddings = None\n",
    "        ids = np.array([])\n",
    "\n",
    "        for filename in os.listdir(embeddings_dir):\n",
    "            if os.path.splitext(filename)[1] == '.npz':\n",
    "                contents = np.load(os.path.join(embeddings_dir, filename), allow_pickle=True)\n",
    "                new_embeddings = contents['embeddings'].item()\n",
    "                new_ids = contents['ids']\n",
    "\n",
    "                if embeddings is None:\n",
    "                    embeddings = new_embeddings\n",
    "                else:\n",
    "                    embeddings = vstack([embeddings, new_embeddings], format='csr')\n",
    "\n",
    "                ids = np.append(ids, new_ids)\n",
    "\n",
    "        return embeddings, ids\n",
    "\n",
    "class Recommender:\n",
    "    def __init__(self, embeddings, ids):\n",
    "        self.embeddings = embeddings\n",
    "        self.ids = ids\n",
    "\n",
    "    @classmethod\n",
    "    def from_dir(cls, embeddings_dir):\n",
    "        embeddings, ids = Embedder.load_embeddings(embeddings_dir)\n",
    "        return cls(embeddings, ids)\n",
    "\n",
    "    def recommend(self, embedding, n=10):\n",
    "        similarity = cosine_similarity(self.embeddings, embedding).flatten()\n",
    "\n",
    "        most_similar_rows = np.argsort(-similarity)\n",
    "        if most_similar_rows[0] == 1:\n",
    "            most_similar_rows = most_similar_rows[1:(n+1)]\n",
    "        else:\n",
    "            most_similar_rows = most_similar_rows[:n]\n",
    "\n",
    "        most_similar_ids = [\n",
    "            int(self.ids[row])\n",
    "            for row in most_similar_rows\n",
    "        ]\n",
    "\n",
    "        return most_similar_ids\n",
    "\n",
    "    def recommend_by_id(self, id, n=10):\n",
    "        assert id in self.ids\n",
    "\n",
    "        row = list(self.ids).index(id)\n",
    "        embedding = self.embeddings[row]\n",
    "\n",
    "        return self.recommend(embedding, n=n+1)[1:]\n",
    "\n",
    "    def recommend_pprint(self, id, titles, n=10):\n",
    "        query_title = ids_to_titles(id, titles)\n",
    "        print(f'Top {n} similar movies to \"{query_title}\":')\n",
    "        for similar_id in self.recommend_by_id(id, n=n):\n",
    "            print(f'* {ids_to_titles(similar_id, titles)}')\n",
    "\n",
    "def ids_to_titles(ids, titles):\n",
    "    if type(ids) == int:\n",
    "        return titles[ids]\n",
    "    return list(map(titles.__getitem__, ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv(os.path.join('data', 'm-st5000', 'tmdb_5000_credits.csv'), index_col='movie_id')\n",
    "movies = pd.read_csv(os.path.join('data', 'm-st5000', 'tmdb_5000_movies.csv'), index_col='id')\n",
    "\n",
    "credits = credits.drop(columns=['title'])\n",
    "movies = movies.join(credits)\n",
    "\n",
    "movies = movies.sample(frac=1, random_state=1)\n",
    "\n",
    "del credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = movies.iloc[:4000, :]\n",
    "test = movies.iloc[4000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "674 in train.index      # Harry Potter and the Goblet of Fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10193 in train.index    # Toy Story 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `vocab_size = 10000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedder in [train] mode.\n",
      "INFO:root:Preprocessing 'overview'\n",
      "INFO:root:Vectorizing 'overview'...\n",
      "INFO:root:Vectorizing 'overview' took 16.632 s, for a vocabulary size of 10000.\n"
     ]
    }
   ],
   "source": [
    "embedder = Embedder()\n",
    "embedder.train(train, vocab_size=10000, embedding_dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedder in [infer] mode.\n",
      "INFO:root:Preprocessing 'overview'\n",
      "INFO:root:Vectorizing 'overview'...\n",
      "INFO:root:Vectorizing 'overview' took 20.4476 s, for a vocabulary size of 10000.\n"
     ]
    }
   ],
   "source": [
    "embeddings, ids = embedder.embed(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = Recommender(embeddings, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies to \"Harry Potter and the Goblet of Fire\":\n",
      "* Harry Potter and the Prisoner of Azkaban\n",
      "* Harry Potter and the Half-Blood Prince\n",
      "* Harry Potter and the Order of the Phoenix\n",
      "* Harry Potter and the Chamber of Secrets\n",
      "* Dude Where's My Dog?\n",
      "* Harry Potter and the Philosopher's Stone\n",
      "* Married Life\n",
      "* My Bloody Valentine\n",
      "* Dante's Peak\n",
      "* Something's Gotta Give\n"
     ]
    }
   ],
   "source": [
    "rec.recommend_pprint(674, movies['title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dude Where's My Dog?*, *Dante's Peak* and *Something's Gotta Give* are\n",
    "particularly interesting: The main character's name is Harry! But they are in\n",
    "entirely different genres as *Harry Potter*. Concrete example of how excluding\n",
    "`genres` does bad things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies to \"Toy Story 3\":\n",
      "* Toy Story\n",
      "* Toy Story 2\n",
      "* The 40 Year Old Virgin\n",
      "* Man on the Moon\n",
      "* Heartbeeps\n",
      "* Factory Girl\n",
      "* Class of 1984\n",
      "* A LEGO Brickumentary\n",
      "* The Man\n",
      "* Small Soldiers\n"
     ]
    }
   ],
   "source": [
    "rec.recommend_pprint(10193, movies['title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturing similarity on **Andy**:\n",
    "* *Toy Story 3*: Toys belong to **Andy**.\n",
    "* *The 40 Year Old Virgin*: Main character is **Andy** Stitzer.\n",
    "* *Man on the Moon*: Biopic on **Andy** Kaufman.\n",
    "* *Heartbeeps*: Stars **Andy** Kaufman.\n",
    "* *Factory Girl*: Biopic with **Andy** Warhol as a character.\n",
    "* *The Man*: Main character is **Andy** Fiddler.\n",
    "\n",
    "But again, in different genres."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `vocab_size = 5000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedder in [train] mode.\n",
      "INFO:root:Preprocessing 'overview'\n",
      "INFO:root:Vectorizing 'overview'...\n",
      "INFO:root:Vectorizing 'overview' took 13.9551 s, for a vocabulary size of 5000.\n"
     ]
    }
   ],
   "source": [
    "embedder = Embedder()\n",
    "embedder.train(train, vocab_size=5000, embedding_dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedder in [infer] mode.\n",
      "INFO:root:Preprocessing 'overview'\n",
      "INFO:root:Vectorizing 'overview'...\n",
      "INFO:root:Vectorizing 'overview' took 19.4689 s, for a vocabulary size of 5000.\n"
     ]
    }
   ],
   "source": [
    "embeddings, ids = embedder.embed(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = Recommender(embeddings, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies to \"Harry Potter and the Goblet of Fire\":\n",
      "* Harry Potter and the Prisoner of Azkaban\n",
      "* Harry Potter and the Order of the Phoenix\n",
      "* Harry Potter and the Chamber of Secrets\n",
      "* Harry Potter and the Half-Blood Prince\n",
      "* Dude Where's My Dog?\n",
      "* Harry Potter and the Philosopher's Stone\n",
      "* Something's Gotta Give\n",
      "* Married Life\n",
      "* Dante's Peak\n",
      "* Armageddon\n"
     ]
    }
   ],
   "source": [
    "rec.recommend_pprint(674, movies['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies to \"Toy Story 3\":\n",
      "* Toy Story\n",
      "* Toy Story 2\n",
      "* The 40 Year Old Virgin\n",
      "* Man on the Moon\n",
      "* Class of 1984\n",
      "* Factory Girl\n",
      "* A LEGO Brickumentary\n",
      "* Heartbeeps\n",
      "* The Man\n",
      "* CJ7\n"
     ]
    }
   ],
   "source": [
    "rec.recommend_pprint(10193, movies['title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CJ7* is a Chinese sci-fi film about aliens. Quality starting to degrade slightly?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `vocab_size = 3000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedder in [train] mode.\n",
      "INFO:root:Preprocessing 'overview'\n",
      "INFO:root:Vectorizing 'overview'...\n",
      "INFO:root:Vectorizing 'overview' took 19.199 s, for a vocabulary size of 3000.\n"
     ]
    }
   ],
   "source": [
    "embedder = Embedder()\n",
    "embedder.train(train, vocab_size=3000, embedding_dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedder in [infer] mode.\n",
      "INFO:root:Preprocessing 'overview'\n",
      "INFO:root:Vectorizing 'overview'...\n",
      "INFO:root:Vectorizing 'overview' took 18.4673 s, for a vocabulary size of 3000.\n"
     ]
    }
   ],
   "source": [
    "embeddings, ids = embedder.embed(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = Recommender(embeddings, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies to \"Harry Potter and the Goblet of Fire\":\n",
      "* Harry Potter and the Prisoner of Azkaban\n",
      "* Harry Potter and the Order of the Phoenix\n",
      "* Dude Where's My Dog?\n",
      "* Married Life\n",
      "* Something's Gotta Give\n",
      "* Harry Potter and the Chamber of Secrets\n",
      "* Harry Potter and the Half-Blood Prince\n",
      "* Dante's Peak\n",
      "* Harry Potter and the Philosopher's Stone\n",
      "* The Greatest Game Ever Played\n"
     ]
    }
   ],
   "source": [
    "rec.recommend_pprint(674, movies['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies to \"Toy Story 3\":\n",
      "* Toy Story 2\n",
      "* Toy Story\n",
      "* The 40 Year Old Virgin\n",
      "* Class of 1984\n",
      "* Factory Girl\n",
      "* Man on the Moon\n",
      "* Heartbeeps\n",
      "* A LEGO Brickumentary\n",
      "* The Man\n",
      "* CJ7\n"
     ]
    }
   ],
   "source": [
    "rec.recommend_pprint(10193, movies['title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `vocab_size = 1000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedder in [train] mode.\n",
      "INFO:root:Preprocessing 'overview'\n",
      "INFO:root:Vectorizing 'overview'...\n",
      "INFO:root:Vectorizing 'overview' took 16.1751 s, for a vocabulary size of 3000.\n"
     ]
    }
   ],
   "source": [
    "embedder = Embedder()\n",
    "embedder.train(train, vocab_size=1000, embedding_dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedder in [infer] mode.\n",
      "INFO:root:Preprocessing 'overview'\n",
      "INFO:root:Vectorizing 'overview'...\n",
      "INFO:root:Vectorizing 'overview' took 23.0758 s, for a vocabulary size of 3000.\n"
     ]
    }
   ],
   "source": [
    "embeddings, ids = embedder.embed(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = Recommender(embeddings, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies to \"Harry Potter and the Goblet of Fire\":\n",
      "* Harry Potter and the Prisoner of Azkaban\n",
      "* Harry Potter and the Order of the Phoenix\n",
      "* Dude Where's My Dog?\n",
      "* Married Life\n",
      "* Something's Gotta Give\n",
      "* Harry Potter and the Chamber of Secrets\n",
      "* Harry Potter and the Half-Blood Prince\n",
      "* Dante's Peak\n",
      "* Harry Potter and the Philosopher's Stone\n",
      "* The Greatest Game Ever Played\n"
     ]
    }
   ],
   "source": [
    "rec.recommend_pprint(674, movies['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies to \"Toy Story 3\":\n",
      "* Toy Story 2\n",
      "* Toy Story\n",
      "* The 40 Year Old Virgin\n",
      "* Class of 1984\n",
      "* Factory Girl\n",
      "* Man on the Moon\n",
      "* Heartbeeps\n",
      "* A LEGO Brickumentary\n",
      "* The Man\n",
      "* CJ7\n"
     ]
    }
   ],
   "source": [
    "rec.recommend_pprint(10193, movies['title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality of recommendations seems to be pretty constant even after decreasing vocabulary size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>Vocab size</th>\n",
    "        <th>Coverage</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1000</td>\n",
    "        <td>80%</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3000</td>\n",
    "        <td>95%</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>5000</td>\n",
    "        <td>98%</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1000</td>\n",
    "        <td>99%</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "C1 (proficient/advanced) user knows about 8000 words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless, no harm in erring on the side of a larger vocabulary. Processing\n",
    "time is not sensitive to vocabulary size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `vocab_size = 5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedder in [train] mode.\n",
      "INFO:root:Preprocessing 'overview'\n",
      "INFO:root:Vectorizing 'overview'...\n",
      "INFO:root:Vectorizing 'overview' took 16.5855 s, for a vocabulary size of 5.\n"
     ]
    }
   ],
   "source": [
    "embedder = Embedder()\n",
    "embedder.train(train, vocab_size=5, embedding_dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedder in [infer] mode.\n",
      "INFO:root:Preprocessing 'overview'\n",
      "INFO:root:Vectorizing 'overview'...\n",
      "INFO:root:Vectorizing 'overview' took 18.5251 s, for a vocabulary size of 5.\n"
     ]
    }
   ],
   "source": [
    "embeddings, ids = embedder.embed(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = Recommender(embeddings, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies to \"Harry Potter and the Goblet of Fire\":\n",
      "* Drinking Buddies\n",
      "* Butterfly Girl\n",
      "* Girls Gone Dead\n",
      "* The Salon\n",
      "* The First Great Train Robbery\n",
      "* Obvious Child\n",
      "* 54\n",
      "* The Crew\n",
      "* Sahara\n",
      "* All Superheroes Must Die\n"
     ]
    }
   ],
   "source": [
    "rec.recommend_pprint(674, movies['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['life', 'man', 'new', 'world', 'young'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.get_vocab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
